export class AudioProcessingService {
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private processor: ScriptProcessorNode | null = null;
  private stream: MediaStream | null = null;
  private isRecording = false;

  constructor(
    private onAudioChunk: (chunk: string) => void,
    private onAudioLevel: (level: number) => void,
    private onError: (error: Error) => void
  ) {}

  async requestMicrophonePermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      stream.getTracks().forEach(track => track.stop());
      return true;
    } catch (error) {
      this.onError(new Error('Microphone permission denied'));
      return false;
    }
  }

  async startRecording(): Promise<void> {
    try {
      console.log('üé§ Starting audio recording...');
      
      // Request media stream with specific constraints for Gemini
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: { ideal: 16000 },
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      // Create audio context with 16kHz sample rate (required by Gemini)
      this.audioContext = new AudioContext({ sampleRate: 16000 });
      const source = this.audioContext.createMediaStreamSource(this.stream);
      
      console.log('üîä Audio context sample rate:', this.audioContext.sampleRate);
      
      // Set up analyser for audio level monitoring
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 256;
      this.analyser.smoothingTimeConstant = 0.8;
      source.connect(this.analyser);
      
      // Create script processor for real-time audio processing
      this.processor = this.audioContext.createScriptProcessor(1024, 1, 1);
      this.processor.onaudioprocess = this.processAudioChunk.bind(this);
      
      source.connect(this.processor);
      this.processor.connect(this.audioContext.destination);
      
      this.isRecording = true;
      this.startAudioLevelMonitoring();
      
      console.log('‚úÖ Audio recording started successfully');
    } catch (error) {
      console.error('‚ùå Failed to start recording:', error);
      this.onError(new Error('Failed to start recording: ' + (error as Error).message));
      throw error;
    }
  }

  private processAudioChunk(event: AudioProcessingEvent): void {
    if (!this.isRecording) return;

    const inputBuffer = event.inputBuffer;
    const inputData = inputBuffer.getChannelData(0);
    
    // Convert Float32Array to Int16Array (16-bit PCM as required by Gemini)
    const pcmData = new Int16Array(inputData.length);
    for (let i = 0; i < inputData.length; i++) {
      // Clamp values to 16-bit signed integer range
      const sample = Math.max(-1, Math.min(1, inputData[i]));
      pcmData[i] = Math.floor(sample * 32767);
    }
    
    // Convert to base64 for WebSocket transmission
    const base64Data = this.arrayBufferToBase64(pcmData.buffer);
    this.onAudioChunk(base64Data);
  }

  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  private startAudioLevelMonitoring(): void {
    if (!this.analyser) return;

    const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
    
    const updateLevel = () => {
      if (!this.isRecording || !this.analyser) return;
      
      this.analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      const level = Math.min(100, (average / 128) * 100);
      
      this.onAudioLevel(level);
      requestAnimationFrame(updateLevel);
    };
    
    updateLevel();
  }

  stopRecording(): void {
    this.isRecording = false;
    
    if (this.processor) {
      this.processor.disconnect();
      this.processor = null;
    }
    
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
    
    this.analyser = null;
  }

  getRecordingStatus(): boolean {
    return this.isRecording;
  }
}